{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epsylon-greedy Method\n",
    "\n",
    "This notebook is was built by Camille-Amaury JUGE in order to better understands the epsylon-greedy RL method. \n",
    "\n",
    "We will construct an agent which will try to find its path in a matrix (labyrinth) without walls.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "import random\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Labyrinth(object):\n",
    "    def __init__(self, x, y, max_reward, punition, final_pos):\n",
    "        super(Labyrinth, self).__init__()\n",
    "        self.lab = np.array([np.array([punition for j in range(y)]) for i in range(x)])\n",
    "        self.lab[final_pos[0]][final_pos[1]] = max_reward\n",
    "        print(self.lab)\n",
    "        \n",
    "    def update_Pos(self, x, y, direction):\n",
    "        if (y == 0 and direction == 0) or (y == self.lab.shape[1]-1 and direction == 1) or (x == 0 and direction == 2) or (x == self.lab.shape[0]-1 and direction == 3):\n",
    "            pass\n",
    "        else:\n",
    "            y = y + (-1 if direction == 0 else (1 if direction == 1 else 0))\n",
    "            x = x + (-1 if direction == 2 else (1 if direction == 3 else 0))\n",
    "        return (x,y)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Robot(object):\n",
    "    def __init__(self, init_pos, final_pos, lab, experiencing_rate, decreasing_exp_rate, learning_rate):\n",
    "        super(Robot, self).__init__()\n",
    "        self.init_pos = init_pos\n",
    "        self.pos = self.init_pos\n",
    "        self.final_pos = final_pos\n",
    "        self.actions = [\"Left\", \"Right\", \"Top\", \"Bottom\"]\n",
    "        self.labyrinth = lab\n",
    "        self.Q = np.zeros((self.labyrinth.lab.shape[0], self.labyrinth.lab.shape[1], len(self.actions)))\n",
    "        self.init_rates = [experiencing_rate, decreasing_exp_rate, learning_rate]\n",
    "        self.rates = self.init_rates\n",
    "        \n",
    "    def play(self, epoch, max_iteration_per_epoch):\n",
    "        for i in range(epoch):\n",
    "            exploring = (random.uniform(0, 1) < self.rates[0])\n",
    "            self.history = []\n",
    "            self.pos = self.init_pos\n",
    "            iteration = 0\n",
    "            \n",
    "            while((self.pos != self.final_pos) and (iteration < max_iteration_per_epoch)):\n",
    "                action = self.choose_action(exploring)\n",
    "                if action == \"Left\":\n",
    "                    self.history.append((self.pos[0], self.pos[1], 0))\n",
    "                    self.pos = self.labyrinth.update_Pos(self.pos[0], self.pos[1], 0)\n",
    "                if action == \"Right\":\n",
    "                    self.history.append((self.pos[0], self.pos[1], 1))\n",
    "                    self.pos = self.labyrinth.update_Pos(self.pos[0], self.pos[1], 1)\n",
    "                if action == \"Top\":\n",
    "                    self.history.append((self.pos[0], self.pos[1], 2))\n",
    "                    self.pos = self.labyrinth.update_Pos(self.pos[0], self.pos[1], 2)\n",
    "                if action == \"Bottom\":\n",
    "                    self.history.append((self.pos[0], self.pos[1], 3))\n",
    "                    self.pos = self.labyrinth.update_Pos(self.pos[0], self.pos[1], 3)\n",
    "                iteration += 1\n",
    "                \n",
    "                \n",
    "            if self.pos != self.final_pos:\n",
    "                self.history.append((self.final_pos[0],self.final_pos[1],0))\n",
    "                \n",
    "            self.update_Q()\n",
    "            self.rates[0] = self.rates[0] - self.rates[1]\n",
    "            \n",
    "        \n",
    "    def update_Q(self):\n",
    "        sum_reward = 0\n",
    "        for i, pos in enumerate(self.history):\n",
    "            if i != 0:\n",
    "                sum_reward += self.labyrinth.lab[pos[0]][pos[1]]\n",
    "        \n",
    "        weight_update = self.init_rates[2] * sum_reward\n",
    "        for i, pos in enumerate(self.history):\n",
    "            self.Q[pos[0]][pos[1]][pos[2]] += weight_update\n",
    "        \n",
    "                \n",
    "        \n",
    "                \n",
    "        \n",
    "    def choose_action(self, exploring):\n",
    "        # if experiencing then random decision\n",
    "        if exploring:\n",
    "            return self.actions[randint(0, 1)]\n",
    "        # if using memory then maximize rewards\n",
    "        else:\n",
    "            possibilities = self.Q[self.pos[0]][self.pos[1]]\n",
    "            # find max action\n",
    "            max_score = -100000\n",
    "            max_i = -1\n",
    "            for i, score in enumerate(possibilities):\n",
    "                if score > max_score:\n",
    "                    max_i = i\n",
    "                    max_score = score\n",
    "            return self.actions[max_i]\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    def __str__(self):\n",
    "        s = \"\"\n",
    "        for i, rows in enumerate(self.Q):\n",
    "            s += \"|\"\n",
    "            for j, column in enumerate(rows):\n",
    "                if self.final_pos == (i,j):\n",
    "                    s+=\"ðŸž¬|\"\n",
    "                else:\n",
    "                    max_score = -10000000\n",
    "                    max_k = -1\n",
    "                    for k, score in enumerate(column):\n",
    "                        if score > max_score:\n",
    "                            max_k = k\n",
    "                            max_score = score\n",
    "                    if max_k == 0:\n",
    "                        s += \"ðŸ¡„|\"\n",
    "                    elif max_k == 1:\n",
    "                        s += \"ðŸ¡†|\"\n",
    "                    elif max_k == 2:\n",
    "                        s += \"ðŸ¡…|\"\n",
    "                    elif max_k == 3:\n",
    "                        s += \"ðŸ¡‡|\"\n",
    "            s += \"\\n\"\n",
    "        return s\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "_final_position = (0,0)\n",
    "_init_position = (3,9)\n",
    "_lab_dim = (4,10)\n",
    "_rewards = (50,-1)\n",
    "# epsilon rate\n",
    "_experiencing_rate = 0.99\n",
    "_decreasing_exp_rate = 0.000005\n",
    "_learning_rate = 0.0001\n",
    "_epochs = 20000\n",
    "_max_iteration_random = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]]\n"
     ]
    }
   ],
   "source": [
    "lab_1 = Labyrinth(_lab_dim[0], _lab_dim[1], _rewards[0], _rewards[1],_final_position)\n",
    "robot_1 = Robot(_init_position, _final_position, lab_1, _experiencing_rate, _decreasing_exp_rate, _learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function took 10287.480 ms\n"
     ]
    }
   ],
   "source": [
    "time1 = time.time()\n",
    "robot_1.play(_epochs, _max_iteration_random)\n",
    "time2 = time.time()\n",
    "print('function took {:.3f} ms'.format((time2-time1)*1000.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "\n",
    "how to interpret :\n",
    "\n",
    "Arrows represent the way the agent tried to maximize the reward by reaching the X cross."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|ðŸž¬|ðŸ¡„|ðŸ¡„|ðŸ¡„|ðŸ¡„|ðŸ¡„|ðŸ¡„|ðŸ¡„|ðŸ¡„|ðŸ¡„|\n",
      "|ðŸ¡…|ðŸ¡…|ðŸ¡„|ðŸ¡…|ðŸ¡‡|ðŸ¡…|ðŸ¡‡|ðŸ¡‡|ðŸ¡…|ðŸ¡…|\n",
      "|ðŸ¡‡|ðŸ¡…|ðŸ¡„|ðŸ¡„|ðŸ¡„|ðŸ¡„|ðŸ¡„|ðŸ¡„|ðŸ¡„|ðŸ¡„|\n",
      "|ðŸ¡‡|ðŸ¡…|ðŸ¡…|ðŸ¡‡|ðŸ¡‡|ðŸ¡…|ðŸ¡…|ðŸ¡‡|ðŸ¡‡|ðŸ¡…|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(robot_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
